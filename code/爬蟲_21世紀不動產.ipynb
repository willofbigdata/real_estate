{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 準備工作\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "# import bs4\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "db_name = \"../data/21_century.sqlite\"\n",
    "db_url_list = \"../data/21_century_URLs.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 建立紀錄已經看過的內頁url的資料庫\n",
    "# 如果這個資料庫已經被建立過了 就略過\n",
    "\n",
    "# url: 內網url中的ID 具primary key性質\n",
    "# modDate: 檢視內頁的日期跟時間\n",
    "\n",
    "if os.path.isfile(db_url_list) == False:\n",
    "\n",
    "    with sqlite3.connect(db_url_list) as conn_id_list:\n",
    "        \n",
    "        c = conn_id_list.cursor()\n",
    "        \n",
    "        c.execute(\"\"\"CREATE TABLE urlList(\n",
    "        url text unique not null,\n",
    "        modDate datetime \n",
    "        )\"\"\")\n",
    "\n",
    "    conn_id_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 建立儲存內頁url跟內頁內容用的資料庫\n",
    "# 如果這個資料庫已經被建立過了 就略過\n",
    "\n",
    "# url: 內網url 具primary key性質\n",
    "# soup: 內頁內容\n",
    "# nosql: 用於紀錄資料紀錄於nosql資料庫的狀態\n",
    "# rdb: 用於紀錄資料紀錄於sql資料庫的狀態\n",
    "# getTime: 紀錄內頁的日期跟時間\n",
    "\n",
    "if os.path.isfile(db_name) == False:\n",
    "\n",
    "    with sqlite3.connect(db_name) as conn:\n",
    "        \n",
    "        c = conn.cursor()\n",
    "        \n",
    "        c.execute(\"\"\"CREATE TABLE rental(\n",
    "        url text unique not null,\n",
    "        soup text not null,\n",
    "        nosql text,\n",
    "        rdb text,\n",
    "        getTime datetime \n",
    "        )\"\"\")\n",
    "        \n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定義 insert_urls() 方法\n",
    "\n",
    "# 將爬下來的ID存到爬過的url紀錄中\n",
    "\n",
    "# 參數: \n",
    "# db_name: 要塞的資料庫名稱(sqlite檔案)\n",
    "# id_list: 含有內頁ID的list\n",
    "\n",
    "def insert_urls(db_url_list, id_list):\n",
    "    \n",
    "    with sqlite3.connect(db_url_list) as conn_insert_url:\n",
    "               \n",
    "        c_iu = conn_insert_url.cursor()\n",
    "\n",
    "        print(id_list)\n",
    "        \n",
    "        for each_id in id_list:\n",
    "        \n",
    "            try:\n",
    "        \n",
    "                today = datetime.datetime.today()\n",
    "                today = today.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                values = \"'http://www.century21.com.tw/index/Rental/RentPage/\" + str(each_id) + \"','\" + str(today) + \"'\"       \n",
    "\n",
    "                insertString = \"INSERT INTO urlList (url, modDate) VALUES(\" + values + \");\"\n",
    "                c_iu.execute(insertString)\n",
    "            \n",
    "            except Exception as e:\n",
    "                \n",
    "                print(\"例外: \" + str(e))\n",
    "                print(each_id)\n",
    "            \n",
    "    c_iu.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 找出所有已經被爬過的內頁url\n",
    "\n",
    "with sqlite3.connect(db_name) as retr_url:\n",
    "        \n",
    "    c = retr_url.cursor()\n",
    "\n",
    "    c.execute(\"SELECT url from rental\")\n",
    "    url_completed = c.fetchall()\n",
    "    \n",
    "retr_url.close()\n",
    "# url_completed[0][0][-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定義 crawl_links_single() 方法\n",
    "# 從一個外網頁面找出該頁面裡所有的內頁ID\n",
    "\n",
    "def crawl_links_single(driver):\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    soup_hrefs = soup.select('div[class=\"main clearfix\"] > div > a')\n",
    "    hrefs = []\n",
    "\n",
    "    for each in soup_hrefs:\n",
    "        hrefs.append(each['href'].split('/')[-1])\n",
    "#         hrefs.append(each['href'])\n",
    "\n",
    "    return hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定義 crawl_n_insert() 方法\n",
    "# 爬內頁然後儲存內容到資料庫中\n",
    "\n",
    "def crawl_n_insert(url, db_name):\n",
    "    \n",
    "#     driver = webdriver.PhantomJS()\n",
    "#     driver.get(url)\n",
    "#     time.sleep(2.5)\n",
    "#     page_source = str(driver.page_source)\n",
    "    page_source = requests.get(url)\n",
    "    page_source = str(page_source.text)\n",
    "    \n",
    "    # 處理引號\n",
    "    \n",
    "    page_source = page_source.replace(\"\\\"\",\"\\\"\\\"\")\n",
    "    page_source = page_source.replace('\\'',\"\\'\\'\")\n",
    "    \n",
    "    with sqlite3.connect(db_name) as conn_insert_page:\n",
    "               \n",
    "        c_ip = conn_insert_page.cursor()\n",
    "        \n",
    "        try:\n",
    "\n",
    "            today = datetime.datetime.today()\n",
    "            today = today.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            values = \"\\\"\" + str(url) + \"\\\",'\" + page_source + \"','','','\" + str(today) + \"'\"\n",
    "\n",
    "#             print(values)\n",
    "\n",
    "            insertString = \"INSERT INTO rental (url, soup, nosql, rdb, getTime) VALUES(\" + values + \");\"\n",
    "\n",
    "#             print(insertString)\n",
    "\n",
    "            c_ip.execute(insertString)\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(url)\n",
    "            print(\"例外: \" + str(e))\n",
    "        finally:\n",
    "            c_ip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 主程序1:\n",
    "# 從外網把所有的內頁url爬下來\n",
    "\n",
    "main_url = \"http://www.century21.com.tw/index/Rental/Rent\"\n",
    "\n",
    "end_loop = False\n",
    "driver = webdriver.PhantomJS()\n",
    "driver.get(main_url)\n",
    "time.sleep(2.5)\n",
    "\n",
    "while not end_loop:\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        print(driver.current_url)\n",
    "        id_list = crawl_links_single(driver)\n",
    "        return_count = len(id_list)\n",
    "\n",
    "        if return_count > 0:\n",
    "            insert_urls(db_url_list, id_list)\n",
    "    \n",
    "        driver.find_element_by_link_text(\"下一頁\").click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        print(\"例外: \" + str(driver.current_url) + \" \\r; \" + str(e))\n",
    "        end_loop = True\n",
    "        \n",
    "print(\"內頁url搜尋結束\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 檢查 db_url_list 結果\n",
    "\n",
    "with sqlite3.connect(db_url_list) as conn_url_list:\n",
    "    \n",
    "    c_ul = conn_url_list.cursor()\n",
    "    qryString = \"SELECT distinct count(*) from urlList limit 1;\"\n",
    "    c_ul.execute(qryString)\n",
    "    results = c_ul.fetchall()\n",
    "\n",
    "c_ul.close()\n",
    "\n",
    "print((results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 主程序2:\n",
    "# 從外網把所有的內頁內容爬下來\n",
    "\n",
    "# 取得所有的url\n",
    "\n",
    "with sqlite3.connect(db_url_list) as conn_call_list:\n",
    "    \n",
    "    c_cl = conn_url_list.cursor()\n",
    "    qryString = \"SELECT url from urlList;\"\n",
    "    c_cl.execute(qryString)\n",
    "    results = c_cl.fetchall()\n",
    "\n",
    "c_cl.close()\n",
    "\n",
    "# 略過已經做過的網址\n",
    "        \n",
    "for each in results:\n",
    "    try:\n",
    "        print(each[0])\n",
    "        crawl_n_insert(each[0],db_name)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "print(\"所有的內頁內容都已爬過且儲存到資料庫中\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 檢查 db_name 結果\n",
    "\n",
    "with sqlite3.connect(db_name) as conn_db_name:\n",
    "    \n",
    "    c_dn = conn_db_name.cursor()\n",
    "    qryString = \"SELECT count(url) from rental;\"\n",
    "    c_dn.execute(qryString)\n",
    "    results = c_dn.fetchall()\n",
    "\n",
    "c_dn.close()\n",
    "    \n",
    "print((results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
